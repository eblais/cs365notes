---
  title: 5. Time Complexity
  author: Eric Blais
  layout: post
  cover: assets/images/rabbit.png
---

Computability theory establishes the ultimate limitations of Turing machines.
That is, decidable languages are the ones that cannot be computed by Turing machines even when our only requirement is that they always halt after some finite number of computational steps.
But we can also ask about which languages can be computed "efficiently" by adding more restrictions to the Turing machines we consider.
Doing so leads us to _complexity theory_.

In this first lecture on complexity theory, we consider what is possibly the most natural resource that we might want to restrict: _time_.


## Multi-Tape Turing Machines

Before we introduce the formal definitions for the study of time complexity, we first extend our notion of Turing machines slightly.
A _multi-tape Turing Machine_ is defined exactly as the one-tape Turing machines we have considered
until now, except that they have access to $$k$$ tapes instead of one for some constant $$k \ge 1$$.
More precisely, each tape contains a different string.
The machine has $$k$$ tape heads, one for each tape.
Each tape head sees exactly one symbol of its current tape.
The computation steps performed by a multi-tape Turing machine depend on its internal state as well as the $$k$$ symbols that it sees with its tape heads.

The tape heads of a multi-tape Turing machine move independently from each other.
For convenience, we let the machine have three possible movement option for each tape head.
They can move Left or Right one square, as before, or they can Stay on the current square.

The _input_ to a two-tape Turing machine will always be the initial content of the first tape when execution begins.
The other $$k-1$$ tapes will always begin empty.

Multi-tape Turing machines give us access to a more powerful Universal Turing Machine.

> **Theorem 1.** _(Hennie and Stearns[^1])_
> There is a two-tape Universal Turing Machine $$U$$ such that for every multi-tape Turing machine $$M$$ and every input $$x \in \{0,1\}^*$$, when the input to $$U$$ is the string $$\left< M \right> x$$ then $$U$$ simulates the execution of $$M$$ on input $$x$$.
> Moreover, when $$M$$'s execution on $$x$$ halts after $$t$$ computational steps, then
> $$U$$'s simulation of $$M$$ halts after $$O( t \log t)$$ steps, where the constant in the $$O(\cdot )$$ notation depends on $$M$$ but not on $$x$$.
{: .block-danger}


> **Proof.**
> (...)



## Time Complexity Classes

The _time cost_ of the (one-tape or multi-tape) Turing machine $$M$$ on input $$x \in \{0,1\}^*$$ is the number of computational steps that $$M$$ performs on that input before it halts.
When $$M$$ does not halt on input $$x$$, its time cost can be defined to be $$\infty$$, but from now on we will only consider Turing machines that halt on all inputs.

From the time cost of a Turing machine on individual inputs, we can obtain a _global_ measure of its time cost.

> **Definition.**
> The _(worst-case) time cost_ of the Turing machine $$M$$ is the function $$t_M : \mathbb{N} \to \mathbb{N}$$ where $$t_M(n)$$ is the maximum time cost of $$M$$ on any input $$x \in \{0,1\}^n$$ of length $$n$$.
{: .block-tip}

With this notion of time cost of individual Turing machines, we can refine the class of all decidable languages into various _time complexity_ classes.

> **Definition.**
> For every function $$f : \mathbb{N} \to \mathbb{N}$$, the _time complexity class_ $$\textbf{TIME}(f)$$ is the set of all languages that can be decided by a multi-tape Turing machine $$M$$ with worst-case time cost $$t_M \le O(f)$$.
{: .block-tip}

By considering various functions, we obtain a number of natural time complexity classes:

Time Class             | Definition
---               | ---
Constant time     | $$\mathbf{TIME}(1)$$
Linear time       | $$\mathbf{LIN} = \mathbf{TIME}(n)$$
Quasi-linear time | $$\bigcup_{k \ge 0} \mathbf{TIME}(n \log^k(n))$$
Quadratic time    | $$\mathbf{TIME}(n^2)$$
Polynomial time   | $$\mathbf{P} = \bigcup_{k \ge 0} \mathbf{TIME}(n^k)$$
Linear-exponential time | $$\mathbf{E} = \mathbf{TIME}(2^{O(n)})$$
Exponential time  | $$\mathbf{EXP} = \bigcup_{k \ge 0} \mathbf{TIME}(2^{n^k})$$
Double exponential time | $$\mathbf{EEXP} = \bigcup_{k \ge 0} \mathbf{TIME}(2^{2^{n^k}})$$
Iterated exponential time | $$\mathbf{ELEMENTARY} = \bigcup_{k \ge 0} \mathbf{TIME}(\underbrace{2^{2^{\cdots^{2^n}}}}_{k})$$


## Time Hierarchy Theorem

Once we have defined these time complexity classes, it's natural to ask whether they are all distinct from each other.
In other words, does giving Turing machines more time let them decide more languages?

In the case of linear and quadratic time, we can use the efficient Universal Turing Machine to show that the two classes are indeed distinct.

> **Theorem 1.**
> $$\mathbf{TIME}(n) \subsetneq \mathbf{TIME}(n^2)$$.
{: .block-danger}

> **Proof.**
> Consider the language 
> 
> $$
> A_{TM}^{n^{1.5}} = \{ x = \left< M \right> 0^k : M \mbox{ accepts } x \mbox{ in } \le |x|^{1.5} \mbox{ steps}\}.
> $$
> 
> The language $$A_{TM}^{n^{1.5}}$$ is in $$\mathbf{TIME}(n^2)$$, because the Universal Turing machine $$U$$ augmented with a timer can simulate $$n^{1.5}$$ steps of $$M$$ in time $$O(n^{1.5} \log n) \le O(n^2)$$.
> 
> We now want to show that $$A_{TM}^{n^{1.5}} \notin \mathbf{TIME}(n)$$.
> Assume for the sake of contradiction that it is.
> Let $$T$$ decide $$L$$ in linear time.
> 
> Consider the machine $$D$$ that on input $$x = \left< M \right> 0^k$$ runs $$T$$ on input $$x$$
> and then accepts if and only if $$T$$ rejects.
> The machine $$D$$ also has linear time cost.
> What does $$D$$ do on the input $$x = \left< D \right> 0^k$$?
> When $$k$$ is large enough, then it always halts within at most $$|x|^{1.5}$$ steps.
> So it accepts if and only if $$T$$ rejects, contradicting the assumption that $$T$$ decides $$A_{TM}^{n^{1.5}}$$.

The same idea gives a much more general result known as the _Time Hierarchy Theorem_.
But the statement of this theorem requires one more definition.

> **Definition.**
> The function $$t : \mathbb{N} \to \mathbb{N}$$ is _time-constructible_ if there is a Turing machine that on every input of the form $$0^n$$ for some $$n \ge 1$$ writes $$t(n)$$ on the tape and halts in time $$O(t(n))$$.
{: .block-tip}

All the functions in the table of complexity classes above are time-constructible.
And they are all distinct, as the following theorem shows.

> **Time Hierarchy Theorem.**
> For every pair of functions $$f, g \colon \mathbb{N} \to \mathbb{N}$$ where $$f \log f = o(g)$$ and $$g$$ is time-constructible, $$\mathbf{TIME}(f) \subsetneq \mathbf{TIME}(g)$$.
{: .block-danger}

> **Proof.**
> The idea of the proof is the same as that of Theorem 1.
> Let $h$ be function defined by $$h(n) = g(n) / \lceil \log g(n) \rceil$$.
> Then $$f = o(h)$$ and $$h \log h = O(g)$$.
> Consider the language 
> 
> $$
> A_{TM}^{h(n)} = \{ x = \left< M \right> 0^k : M \mbox{ accepts } x \mbox{ in } \le h(n) \mbox{ steps}\}.
> $$
> 
> The language $$A_{TM}^{h(n)}$$ is in $$\mathbf{TIME}(g)$$.
> We again justify this statement by analyzing the Universal Turing machine $$U$$ augmented with a timer to simulate $$h(n)$$ steps of $$M$$.
> By the time constructability of $$g$$, we can initialize a timer with the value $$h(n)$$ in time $$O(g(n))$$.
> And then we can complete the simulation in time $$O(h(n) \log h(n)) = O(g(n))$$.
> 
> Assume now for the sake of contradiction that $$A_{TM}^{h(n)} \in \mathbf{TIME}(f)$$.
> Let $$T$$ decide $$L$$ in time $$f(n)$$.
> 
> Consider the machine $$D$$ that on input $$x = \left< M \right> 0^k$$ runs $$T$$ on input $$x$$
> and then accepts if and only if $$T$$ rejects.
> The machine $$D$$ has time cost $$O(f(n))$$.
> What does $$D$$ do on the input $$x = \left< D \right> 0^k$$?
> Since $$f = o(h)$$, when $$k$$ is large enough, then $$D$$ halts within at most $$h(n)$$ steps.
> So it accepts if and only if $$T$$ rejects, contradicting the assumption that $$T$$ decides $$A_{TM}^{h(n)}$$.

Is the time constructability condition in the theorem statement necessary?
It might be tempting to try to generalize the Time Hierarchy Theorem even further so that it holds for _all_ pairs of functions $$f,g$$ that satisfy $$f \log f = o(g)$$.
But such a conjectured generalization does not hold.
The _(Time Hierarchy) Gap Theorem_ shows that it is in fact possible to design a function $$f$$ for which $$\mathbf{TIME}(f(n)) = \mathbf{TIME}(2^{f(n)})$$.
(Needless to say, this function $$f$$ is not time-constructible; it also happens to be extremely fast growing.)

---

_Eric Blais &copy;2023 &mdash; Last edited on Dec. 20, 2023_

---

[^1]: F.C. Hennie and R.E. Stearns. [Two-tape simulation of multitape Turing machines](https://doi.org/10.1145/321356.321362), J.ACM 13(4): 533-546, 1966.
